# This is DEMONSTRATION master config file for the DAS Framework
# All variables used must be specified in this file. 
#
# In practice, this file should be *COPIED* for running experiments. 
# Copies for experiments should go in the "configs/" directory.
#
# 

# LOCATIONS can be:
# s3://bucket/prefix -- A S3 location
# hdfs://            -- An HDFS location. Note that HDFS is lost when a cluster is killed.
# /full/path         -- A path in the local file system. Also lost when a cluster is killed.
#
# For the master config file, all locations are specified in the local file system.
# This allows the master config file to be used with any invocation option.

# Note that we use variable substitution allowable by the Python ConfigParser

[DEFAULT]
# root specifies the root location for all files; testdir specifies ???; mode specifies ???
# For the demo, the root in the current directory
name: demo
root: .
testdir: .
mode: 0
loglevel: INFO

[ENVIRONMENT]
# Specifies environment variables that are to be set in subprocesses
DAS_FRAMEWORK_VERSION: 0.0.1

###
### The following sections specify the Python code that will perform the various functions.
### Usage is module_name.function_name
### 

[setup]
setup: demo_setup.setup

[reader]
reader: demo_reader.reader
input_fname: %(root)s/demo.csv

[engine]
engine: demo_engine.engine

[writer]
writer: demo_writer.writer

# Where the data gets written:
output_fname: %(root)s/demo_output.csv

[validator]
validator: demo_validator.validator
results_fname: %(root)s/demo_results.csv

[takedown]
takedown: demo_takedown.takedown
delete_output: True

# Note that for the experiment section, we can define variables
# and an experiment scaffold. If you specify a scaffold, then methods
# experimentSetup() and experimentTakedown are automatically called
[experiment]
scaffold: demo_experiment.scaffold






